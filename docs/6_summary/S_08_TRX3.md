---
sidebar_position: 8
---

# 天融信实习总结

## 一、加签验签

**车路云一体化安全项目** 车联网-百度移动  gateway模块 加签验签

关键词：SHA256withRSA 非对称加密 前端私钥加签 后端公钥验签  

目的：确保数据不被篡改。

**前端加签流程：**

- 准备并处理数据：准备请求数据（如参数、请求体）和时间戳。将请求数据对象序列化为 JSON 字符串，并移除其中的所有双引号 " 和方括号 [, ]，以确保与后端解析格式一致。
- 拼接字符串：将处理后的数据字符串与时间戳进行拼接。
- 生成签名：使用 SHA256withRSA 算法和前端存储的私钥，对拼接后的字符串进行签名。具体过程是先对字符串计算 SHA-256 哈希，再用私钥加密该哈希值。
- 编码签名：将生成的签名（通常为十六进制格式）转换为 Base64 编码字符串。
- 添加签名到请求头：将生成的签名、时间戳和其他必要信息（如随机字符串）添加到请求的头部或参数中，向后端发送请求。
- 发送请求：将 Base64 编码的签名、原始时间戳以及其他必要信息添加到 HTTP 请求头中，然后发送请求。

**后端验签流程：**

- 选择哈希算法，并准备公钥。
- 重建原始数据：将收到的请求数据 data 与时间戳 timestamp 按照与前端完全相同的规则进行拼接和预处理（例如：去引号、去括号等）。
- 初始化验签对象：创建 Signature 实例，指定算法为 SHA256withRSA，并传入公钥进行初始化。
- 更新待验数据：将重建后的原始数据传入 sig.update(...)。
- 执行验签：调用 sig.verify(signatureBytes)。该方法会：
  - 对传入的数据计算 SHA-256 哈希。
  - 使用公钥解密收到的 Base64 签名，得到哈希摘要。
  - 比较两个哈希值。
- 返回结果：verify() 方法返回 true 表示验签成功，false 表示失败。

**遇到的问题：**

- 请求会依次经过多个 Filter，最后到达 Controller。验签在自定义过滤器中处理。如果过滤器顺序不当，会导致：
  - 验签失败（数据已被修改）
  - 无法获取原始请求体（被其他过滤器提前消费）已经消费了请求体，需要重新构建请求。
  - 性能浪费（对非法请求也进行业务处理）

**错误做法及后果：**

- 验签过滤器在 CharacterEncodingFilter 之前   可能出现乱码，导致签名计算错误
- 验签过滤器在请求体缓存过滤器之前  ❌ 无法读取 InputStream，或读取为空，验签必失败
- 验签在 @RequestBody 绑定之后   ❌ 请求体已被消费，无法获取原始 JSON
- 验签放在权限认证之后  ❌ 对非法请求也进行登录态检查，浪费资源

**SHA256withRSA**

SHA256withRSA实际上是两种算法的组合：SHA-256和RSA。SHA-256是一种哈希算法，用于生成消息的摘要，而RSA是一种非对称加密算法，用于数字签名和验证。SHA256withRSA方法结合了这两种算法的优点，既能确保消息的完整性，又能验证消息的来源。

**加签验签**

发送方用一个哈希函数从报文文本中生成报文摘要，然后用自己的私钥对这个摘要进行加密，得到的就是这个报文对应的数字签名。通常来说，发送方会把数字签名和报文明文一并发送给接受者（因为验签的话，终究需要一个对比的对象）。

接收方同时接收到数字签名和报文明文后，会使用发送方的公钥来对数字签名进行解密，得到一个报文摘要A；同时使用相同的哈希函数对报文明文进行hash处理，得到一个报文摘要B，最后对比报文摘要A和报文摘要B的内容，即可确定内容是否被中间人篡改过。

**数字签名有两种功效**：

- 一是能确定消息确实是由发送方签名并发出来的，因为别人假冒不了发送方的签名。
- 二是数字签名能确定消息的完整性。

## 二、威胁情报去重存储

**僵尸网络木马和蠕虫监测与处置系统**

对威胁情报、攻击检查和僵尸主机规则库进行常态化上报，分为自动上报和手动上报。自动上报指的是定时收集（从IDP检测设备或ES）并解析数据，存储到pgSQL中，每周定时把pgSQL中的数据上报到FTP/ES，然后删除数据，进行下一轮的上报；若自动上报失败可以进行手动补报，手动发起一个上报数据请求进行补报。

**攻击检查规则库/僵尸主机规则库**：

- 每周一 晚上1点，先truncate清空数据库数据，然后定时从idp检测设备读取存储数据，完成上报。

**威胁情报**：

- 去重存储：定时任务，每天定时从ES索引中读取数据，进行格式转换后，在SQL端去重存储。
- 定时上报：每周一定时将postgreSQL中的数据上报到部侧ES。
- 定时删除：每周一上报完成之后，删除上周的postgreSQL中的数据。

**遇到的问题**：

- 去重存储：
  - 常规做法：在Java层约束，先查表中数据，若存在此值，则过滤掉；否则，正常保存。
  - 在数据量很大的时候，百千万条数据时，光查询就很耗时，影响性能。因此我们不在代码层约束，而是直接在sql层约束，过滤掉重复数据。
  - INSERT INTO jmr_threat_intelligence () VALUES () ON CONFLICT DO NOTHING
